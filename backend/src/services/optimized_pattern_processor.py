"""
OptimizedPatternProcessor - ê³ ì„±ëŠ¥ íƒ€ì´í•‘ íŒ¨í„´ ì‹¤ì‹œê°„ ì²˜ë¦¬

T092: íƒ€ì´í•‘ íŒ¨í„´ ì‹¤ì‹œê°„ ì²˜ë¦¬ ì„±ëŠ¥ íŠœë‹
- 50ms ë¯¸ë§Œ í‚¤ ì…ë ¥ ë ˆì´í„´ì‹œ ëª©í‘œ
- ë²„í¼ë§ ë° ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì²˜ë¦¬ëŸ‰ ìµœì í™”
- ë©”ëª¨ë¦¬ í’€ê³¼ ì¬ì‚¬ìš©ìœ¼ë¡œ GC ì••ë ¥ ê°ì†Œ
- ë¹„ë™ê¸° íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì²˜ë¦¬ ë³‘ëª© í•´ê²°
"""
import asyncio
import time
from typing import Dict, List, Any, Optional, Callable, Deque
from collections import deque
from dataclasses import dataclass, field
from asyncio import Queue, Event
from weakref import WeakSet
import json
import threading
from concurrent.futures import ThreadPoolExecutor

from src.models.typing_pattern import TypingPattern
from src.services.pattern_analysis_service import PatternAnalysisService


@dataclass
class TypingEvent:
    """íƒ€ì´í•‘ ì´ë²¤íŠ¸ ë°ì´í„° í´ë˜ìŠ¤"""
    key: str
    timestamp: float
    event_type: str  # 'keydown' | 'keyup'
    session_id: str
    duration: float = 0.0

    def to_dict(self) -> Dict[str, Any]:
        return {
            'key': self.key,
            'timestamp': self.timestamp,
            'type': self.event_type,
            'duration': self.duration
        }


@dataclass
class ProcessingMetrics:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„°"""
    events_processed: int = 0
    patterns_analyzed: int = 0
    avg_latency_ms: float = 0.0
    max_latency_ms: float = 0.0
    buffer_size: int = 0
    processing_rate: float = 0.0  # events per second
    last_reset_time: float = field(default_factory=time.time)

    def reset(self) -> None:
        """ë©”íŠ¸ë¦­ ì´ˆê¸°í™”"""
        self.events_processed = 0
        self.patterns_analyzed = 0
        self.avg_latency_ms = 0.0
        self.max_latency_ms = 0.0
        self.processing_rate = 0.0
        self.last_reset_time = time.time()


@dataclass
class EventBuffer:
    """ê³ ì„±ëŠ¥ ì´ë²¤íŠ¸ ë²„í¼"""
    events: Deque[TypingEvent] = field(default_factory=deque)
    max_size: int = 1000
    last_processed: float = 0.0

    def add_event(self, event: TypingEvent) -> None:
        """ì´ë²¤íŠ¸ ì¶”ê°€ (FIFO, í¬ê¸° ì œí•œ)"""
        if len(self.events) >= self.max_size:
            self.events.popleft()  # O(1) ì—°ì‚°
        self.events.append(event)

    def get_recent_events(self, window_ms: int = 5000) -> List[TypingEvent]:
        """ìµœê·¼ ìœˆë„ìš° ë‚´ ì´ë²¤íŠ¸ ë°˜í™˜"""
        now = time.time() * 1000
        cutoff = now - window_ms

        # dequeëŠ” ì˜¤ë¥¸ìª½ë¶€í„° ìˆœíšŒí•˜ëŠ” ê²ƒì´ íš¨ìœ¨ì 
        recent_events = []
        for event in reversed(self.events):
            if event.timestamp >= cutoff:
                recent_events.append(event)
            else:
                break  # ì •ë ¬ëœ ìƒíƒœì´ë¯€ë¡œ ì¤‘ë‹¨ ê°€ëŠ¥

        return list(reversed(recent_events))

    def clear_old_events(self, max_age_ms: int = 30000) -> int:
        """ì˜¤ë˜ëœ ì´ë²¤íŠ¸ ì •ë¦¬"""
        now = time.time() * 1000
        cutoff = now - max_age_ms
        removed = 0

        while self.events and self.events[0].timestamp < cutoff:
            self.events.popleft()
            removed += 1

        return removed


class OptimizedPatternProcessor:
    """ê³ ì„±ëŠ¥ íƒ€ì´í•‘ íŒ¨í„´ ì‹¤ì‹œê°„ ì²˜ë¦¬ê¸°"""

    def __init__(
        self,
        max_concurrent_sessions: int = 1000,
        buffer_size_per_session: int = 1000,
        batch_size: int = 50,
        processing_interval_ms: int = 100,
        cleanup_interval_s: int = 60
    ):
        """
        ì´ˆê¸°í™”

        Args:
            max_concurrent_sessions: ìµœëŒ€ ë™ì‹œ ì„¸ì…˜ ìˆ˜
            buffer_size_per_session: ì„¸ì…˜ë‹¹ ë²„í¼ í¬ê¸°
            batch_size: ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸°
            processing_interval_ms: ì²˜ë¦¬ ê°„ê²© (ms)
            cleanup_interval_s: ì •ë¦¬ ê°„ê²© (ì´ˆ)
        """
        self.max_concurrent_sessions = max_concurrent_sessions
        self.buffer_size_per_session = buffer_size_per_session
        self.batch_size = batch_size
        self.processing_interval_ms = processing_interval_ms
        self.cleanup_interval_s = cleanup_interval_s

        # ì„¸ì…˜ë³„ ë²„í¼
        self.session_buffers: Dict[str, EventBuffer] = {}

        # ì²˜ë¦¬ ëŒ€ê¸°ì—´
        self.processing_queue: Queue[str] = Queue(maxsize=max_concurrent_sessions)

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.metrics = ProcessingMetrics()

        # ì´ë²¤íŠ¸ ë° ì œì–´
        self.shutdown_event = Event()
        self.processing_task: Optional[asyncio.Task] = None
        self.cleanup_task: Optional[asyncio.Task] = None

        # íŒ¨í„´ ë¶„ì„ ì„œë¹„ìŠ¤
        self.pattern_service = PatternAnalysisService()

        # ìŠ¤ë ˆë“œ í’€ (CPU ì§‘ì•½ì  ì‘ì—…ìš©)
        self.thread_pool = ThreadPoolExecutor(
            max_workers=min(4, threading.cpu_count()),
            thread_name_prefix="pattern-processor"
        )

        # ì½œë°± ë“±ë¡
        self.pattern_callbacks: WeakSet[Callable] = WeakSet()

        # ìºì‹œ (ìµœê·¼ ë¶„ì„ ê²°ê³¼)
        self.analysis_cache: Dict[str, Dict[str, Any]] = {}
        self.cache_max_size = 500

        print(f"ğŸš€ OptimizedPatternProcessor initialized (max_sessions={max_concurrent_sessions})")

    async def start(self) -> None:
        """í”„ë¡œì„¸ì„œ ì‹œì‘"""
        if self.processing_task and not self.processing_task.done():
            return

        print("âš¡ Starting pattern processor...")
        self.shutdown_event.clear()

        # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì‹œì‘
        self.processing_task = asyncio.create_task(self._processing_loop())
        self.cleanup_task = asyncio.create_task(self._cleanup_loop())

        print("âœ… Pattern processor started")

    async def stop(self) -> None:
        """í”„ë¡œì„¸ì„œ ì¤‘ì§€"""
        print("â¹ï¸  Stopping pattern processor...")

        self.shutdown_event.set()

        # íƒœìŠ¤í¬ ì¢…ë£Œ ëŒ€ê¸°
        if self.processing_task:
            await self.processing_task
        if self.cleanup_task:
            await self.cleanup_task

        # ìŠ¤ë ˆë“œ í’€ ì¢…ë£Œ
        self.thread_pool.shutdown(wait=True)

        print("ğŸ›‘ Pattern processor stopped")

    async def process_typing_event(
        self,
        session_id: str,
        event_data: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """
        íƒ€ì´í•‘ ì´ë²¤íŠ¸ ì²˜ë¦¬ (ê³ ì„±ëŠ¥)

        Args:
            session_id: ì„¸ì…˜ ID
            event_data: ì´ë²¤íŠ¸ ë°ì´í„°

        Returns:
            ì²˜ë¦¬ ê²°ê³¼ (íŒ¨í„´ ì—…ë°ì´íŠ¸ê°€ ìˆëŠ” ê²½ìš°)
        """
        start_time = time.perf_counter()

        try:
            # 1. ì„¸ì…˜ ë²„í¼ í™•ì¸/ìƒì„±
            if session_id not in self.session_buffers:
                if len(self.session_buffers) >= self.max_concurrent_sessions:
                    # LRU ë°©ì‹ìœ¼ë¡œ ì˜¤ë˜ëœ ì„¸ì…˜ ì œê±°
                    await self._evict_oldest_session()

                self.session_buffers[session_id] = EventBuffer(
                    max_size=self.buffer_size_per_session
                )

            buffer = self.session_buffers[session_id]

            # 2. íƒ€ì´í•‘ ì´ë²¤íŠ¸ ìƒì„±
            typing_event = TypingEvent(
                key=event_data.get('key', ''),
                timestamp=event_data.get('timestamp', time.time() * 1000),
                event_type=event_data.get('type', 'keydown'),
                session_id=session_id,
                duration=event_data.get('duration', 0.0)
            )

            # 3. ë²„í¼ì— ì¶”ê°€ (O(1))
            buffer.add_event(typing_event)

            # 4. ì²˜ë¦¬ ëŒ€ê¸°ì—´ì— ì„¸ì…˜ ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€)
            try:
                self.processing_queue.put_nowait(session_id)
            except asyncio.QueueFull:
                pass  # ì´ë¯¸ ì²˜ë¦¬ ëŒ€ê¸° ì¤‘

            # 5. ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            self.metrics.events_processed += 1
            self.metrics.buffer_size = sum(
                len(buf.events) for buf in self.session_buffers.values()
            )

            # 6. ë ˆì´í„´ì‹œ ì¸¡ì •
            latency_ms = (time.perf_counter() - start_time) * 1000
            self._update_latency_metrics(latency_ms)

            return {"status": "queued", "latency_ms": round(latency_ms, 2)}

        except Exception as e:
            print(f"âŒ Error processing typing event: {e}")
            return {"status": "error", "error": str(e)}

    async def get_session_pattern(self, session_id: str) -> Optional[Dict[str, Any]]:
        """ì„¸ì…˜ì˜ ìµœì‹  íŒ¨í„´ ì¡°íšŒ"""
        if session_id not in self.session_buffers:
            return None

        buffer = self.session_buffers[session_id]
        recent_events = buffer.get_recent_events(window_ms=10000)  # 10ì´ˆ ìœˆë„ìš°

        if len(recent_events) < 10:
            return None

        # ìºì‹œ í™•ì¸
        cache_key = f"{session_id}_{len(recent_events)}_{recent_events[-1].timestamp}"
        if cache_key in self.analysis_cache:
            return self.analysis_cache[cache_key]

        # íŒ¨í„´ ë¶„ì„ (ìŠ¤ë ˆë“œ í’€ì—ì„œ ì‹¤í–‰)
        loop = asyncio.get_event_loop()
        analysis_result = await loop.run_in_executor(
            self.thread_pool,
            self._analyze_events_sync,
            recent_events
        )

        # ìºì‹œ ì €ì¥ (í¬ê¸° ì œí•œ)
        if len(self.analysis_cache) >= self.cache_max_size:
            # LRU ë°©ì‹ìœ¼ë¡œ ì˜¤ë˜ëœ í•­ëª© ì œê±°
            oldest_key = next(iter(self.analysis_cache))
            del self.analysis_cache[oldest_key]

        self.analysis_cache[cache_key] = analysis_result

        return analysis_result

    def get_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        current_time = time.time()
        time_elapsed = current_time - self.metrics.last_reset_time

        if time_elapsed > 0:
            self.metrics.processing_rate = self.metrics.events_processed / time_elapsed

        return {
            "events_processed": self.metrics.events_processed,
            "patterns_analyzed": self.metrics.patterns_analyzed,
            "avg_latency_ms": round(self.metrics.avg_latency_ms, 2),
            "max_latency_ms": round(self.metrics.max_latency_ms, 2),
            "buffer_size": self.metrics.buffer_size,
            "processing_rate": round(self.metrics.processing_rate, 2),
            "active_sessions": len(self.session_buffers),
            "cache_size": len(self.analysis_cache),
            "queue_size": self.processing_queue.qsize(),
            "uptime_seconds": round(time_elapsed, 1)
        }

    def reset_metrics(self) -> None:
        """ë©”íŠ¸ë¦­ ì´ˆê¸°í™”"""
        self.metrics.reset()

    def register_pattern_callback(self, callback: Callable) -> None:
        """íŒ¨í„´ ì—…ë°ì´íŠ¸ ì½œë°± ë“±ë¡"""
        self.pattern_callbacks.add(callback)

    async def _processing_loop(self) -> None:
        """ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ë£¨í”„"""
        print("ğŸ”„ Processing loop started")

        while not self.shutdown_event.is_set():
            try:
                # ì²˜ë¦¬ ê°„ê²©ë§Œí¼ ëŒ€ê¸°
                await asyncio.sleep(self.processing_interval_ms / 1000.0)

                # ë°°ì¹˜ ì²˜ë¦¬
                processed_sessions = []
                batch_count = 0

                while batch_count < self.batch_size and not self.processing_queue.empty():
                    try:
                        session_id = self.processing_queue.get_nowait()
                        if session_id not in processed_sessions:
                            await self._process_session_batch(session_id)
                            processed_sessions.append(session_id)
                            batch_count += 1
                    except asyncio.QueueEmpty:
                        break

                if processed_sessions:
                    print(f"ğŸ“Š Processed {len(processed_sessions)} sessions")

            except Exception as e:
                print(f"âŒ Error in processing loop: {e}")
                await asyncio.sleep(1.0)  # ì˜¤ë¥˜ ì‹œ ì ì‹œ ëŒ€ê¸°

    async def _process_session_batch(self, session_id: str) -> None:
        """ì„¸ì…˜ ë°°ì¹˜ ì²˜ë¦¬"""
        if session_id not in self.session_buffers:
            return

        buffer = self.session_buffers[session_id]
        recent_events = buffer.get_recent_events()

        if len(recent_events) < 10:  # ìµœì†Œ ì´ë²¤íŠ¸ ìˆ˜ ìš”êµ¬
            return

        try:
            # ë¹„ë™ê¸°ë¡œ íŒ¨í„´ ë¶„ì„
            loop = asyncio.get_event_loop()
            analysis_result = await loop.run_in_executor(
                self.thread_pool,
                self._analyze_events_sync,
                recent_events
            )

            # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            self.metrics.patterns_analyzed += 1

            # ì½œë°± í˜¸ì¶œ
            for callback in list(self.pattern_callbacks):
                try:
                    await callback(session_id, analysis_result)
                except Exception as e:
                    print(f"âš ï¸ Callback error: {e}")

        except Exception as e:
            print(f"âŒ Error processing session {session_id}: {e}")

    async def _cleanup_loop(self) -> None:
        """ì •ë¦¬ ë£¨í”„ (ë©”ëª¨ë¦¬ ê´€ë¦¬)"""
        print("ğŸ§¹ Cleanup loop started")

        while not self.shutdown_event.is_set():
            try:
                await asyncio.sleep(self.cleanup_interval_s)

                # ì˜¤ë˜ëœ ì´ë²¤íŠ¸ ì •ë¦¬
                total_removed = 0
                for session_id, buffer in list(self.session_buffers.items()):
                    removed = buffer.clear_old_events(max_age_ms=300000)  # 5ë¶„
                    total_removed += removed

                    # ë¹ˆ ë²„í¼ ì œê±°
                    if not buffer.events:
                        del self.session_buffers[session_id]

                # ìºì‹œ ì •ë¦¬ (í¬ê¸° ì œí•œ)
                if len(self.analysis_cache) > self.cache_max_size * 0.8:
                    items_to_remove = len(self.analysis_cache) - int(self.cache_max_size * 0.6)
                    for i, key in enumerate(list(self.analysis_cache.keys())):
                        if i >= items_to_remove:
                            break
                        del self.analysis_cache[key]

                if total_removed > 0:
                    print(f"ğŸ—‘ï¸  Cleaned up {total_removed} old events")

            except Exception as e:
                print(f"âŒ Error in cleanup loop: {e}")

    async def _evict_oldest_session(self) -> None:
        """ê°€ì¥ ì˜¤ë˜ëœ ì„¸ì…˜ ì œê±° (LRU)"""
        if not self.session_buffers:
            return

        # ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        session_ages = [
            (session_id, buffer.events[-1].timestamp if buffer.events else 0)
            for session_id, buffer in self.session_buffers.items()
        ]

        if session_ages:
            oldest_session = min(session_ages, key=lambda x: x[1])
            del self.session_buffers[oldest_session[0]]
            print(f"ğŸ—‘ï¸ Evicted oldest session: {oldest_session[0]}")

    def _analyze_events_sync(self, events: List[TypingEvent]) -> Dict[str, Any]:
        """ë™ê¸° ì´ë²¤íŠ¸ ë¶„ì„ (ìŠ¤ë ˆë“œ í’€ìš©)"""
        if len(events) < 2:
            return {"error": "insufficient_events"}

        # TypingEventë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        keystroke_data = [event.to_dict() for event in events]

        # ê¸°ë³¸ í†µê³„ ê³„ì‚°
        keydown_events = [e for e in events if e.event_type == 'keydown']

        if len(keydown_events) < 2:
            return {"error": "insufficient_keydown_events"}

        # íƒ€ì´í•‘ ì†ë„ ê³„ì‚°
        time_span = keydown_events[-1].timestamp - keydown_events[0].timestamp
        time_span_seconds = time_span / 1000.0

        if time_span_seconds <= 0:
            return {"error": "invalid_time_span"}

        words_count = len(keydown_events) / 5  # í‰ê·  ë‹¨ì–´ ê¸¸ì´ 5ì ê°€ì •
        wpm = (words_count / time_span_seconds) * 60

        # ê°„ê²© ë¶„ì„
        intervals = []
        for i in range(1, len(keydown_events)):
            interval = keydown_events[i].timestamp - keydown_events[i-1].timestamp
            intervals.append(interval)

        avg_interval = sum(intervals) / len(intervals) if intervals else 0

        # ì¼ì‹œì •ì§€ ë¶„ì„
        pauses = [interval for interval in intervals if interval > 500]
        pause_count = len(pauses)

        # ë¦¬ë“¬ ì¼ê´€ì„± ê³„ì‚°
        if len(intervals) >= 3:
            mean_interval = sum(intervals) / len(intervals)
            variance = sum((x - mean_interval) ** 2 for x in intervals) / len(intervals)
            std_dev = variance ** 0.5
            cv = std_dev / mean_interval if mean_interval > 0 else 1.0
            rhythm_consistency = max(0.0, 1.0 - min(cv, 1.0))
        else:
            rhythm_consistency = 0.0

        return {
            "statistics": {
                "total_keystrokes": len(events),
                "keydown_count": len(keydown_events),
                "words_per_minute": round(wpm, 2),
                "average_interval_ms": round(avg_interval, 2),
                "pause_count": pause_count,
                "rhythm_consistency": round(rhythm_consistency, 3),
                "time_span_seconds": round(time_span_seconds, 2)
            },
            "patterns": {
                "speed_score": min(wpm / 100.0, 1.0),  # 0-1 ì •ê·œí™”
                "rhythm_score": rhythm_consistency,
                "pause_intensity": min(pause_count / 10.0, 1.0),  # 0-1 ì •ê·œí™”
            },
            "keystroke_data": keystroke_data,
            "analysis_timestamp": time.time()
        }

    def _update_latency_metrics(self, latency_ms: float) -> None:
        """ë ˆì´í„´ì‹œ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        if self.metrics.events_processed == 0:
            self.metrics.avg_latency_ms = latency_ms
        else:
            # ì´ë™ í‰ê· 
            alpha = 0.1  # í‰í™œí™” ìƒìˆ˜
            self.metrics.avg_latency_ms = (
                (1 - alpha) * self.metrics.avg_latency_ms +
                alpha * latency_ms
            )

        if latency_ms > self.metrics.max_latency_ms:
            self.metrics.max_latency_ms = latency_ms